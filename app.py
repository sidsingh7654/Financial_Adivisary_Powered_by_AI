# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gk1dDoXleeR0cEqM4ObbVloDnCFtYF8c

# STAGE 1
"""


# Step 1: Import libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# Step 2: Load your dataset
data = pd.read_csv('simulated_financial_data.csv')

# Check the first few rows
print(data.head())

# Step 3: Feature Engineering

# Savings Rate = Savings / Income
data['Savings_Rate'] = data['Savings_Amount'] / data['Mthly_HH_Income']
# Disposable Income = Income - Expense - EMI (already Savings)
data['Disposable_Income'] = data['Savings_Amount']

# Optional: Adjusted Debt to Income Ratio
data['Adjusted_DTI'] = data['Debt_to_Income_Ratio'] * np.where(data['Risk_Tolerance']=='High', 0.8,
                                                               np.where(data['Risk_Tolerance']=='Moderate', 1, 1.2))


# Encode Categorical Variables
categorical_cols = ['Investment_Horizon', 'Risk_Tolerance', 'Preferred_Investment_Type',
                    'Investment_Experience', 'Market_Volatility_Tolerance',
                    'Short_Term_Goal', 'Mid_Term_Goal', 'Long_Term_Goal', 'Goal_Based_Investing']

le = LabelEncoder()
for col in categorical_cols:
    data[col] = le.fit_transform(data[col])

# Stage 1 Target: Recommended_Investment_Percentage
# For now we simulate it as a function of Risk, Horizon, Savings Rate, Investment Experience

data['Recommended_Investment_Percentage'] = (
    data['Risk_Tolerance'] * 4 +
    data['Investment_Horizon'] * 3 +
    data['Savings_Rate'] * 40 +
    data['Disposable_Income'] * 0.0005 +   # Scaled because disposable income is high value
    data['Investment_Experience'] * 2 +
    data['Market_Volatility_Tolerance'] * 2 +
    (100 - data['Debt_to_Income_Ratio']) * 0.2 +  # Lower DTI, higher investable surplus
    np.random.normal(0, 2, len(data))  # Reduced noise for stability
)

# Clip to 0-100%
data['Recommended_Investment_Percentage'] = data['Recommended_Investment_Percentage'].clip(0, 100)

# Step 5: Split Data
X = data.drop(['User_ID', 'Recommended_Investment_Percentage'], axis=1)
y = data['Recommended_Investment_Percentage']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import MinMaxScaler

# Step 6: Min-Max Scaling
scaler = MinMaxScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.ensemble import GradientBoostingRegressor

gb_model = GradientBoostingRegressor(random_state=42)
gb_model.fit(X_train, y_train)

gb_pred = gb_model.predict(X_test)

print("\nGradient Boosting Regressor")
print("MAE:", mean_absolute_error(y_test, gb_pred))
print("R2 Score:", r2_score(y_test, gb_pred))

import joblib
# The variable gb_model was used to store the trained GradientBoostingRegressor
# Assign gb_model to stage1_model before saving it.
stage1_model = gb_model
joblib.dump(stage1_model, "stage1_gbm.pkl")

"""# STAGE 2"""

# Simulating Stage 2 Targets based on risk, horizon, experience, etc.

# Equity Allocation (focused on risk, experience, and capacity)
data['Equity_Allocation'] = (
    data['Risk_Tolerance'] * 8 +
    data['Investment_Horizon'] * 5 +
    data['Investment_Experience'] * 4 +
    data['Market_Volatility_Tolerance'] * 3 +
    data['Savings_Rate'] * 30 +
    np.random.normal(0, 1.5, len(data))
).clip(0, 100)

# Debt Allocation (focused on risk aversion and short-term needs)
data['Debt_Allocation'] = (
    (5 - data['Risk_Tolerance']) * 6 +  # More allocation if risk tolerance is low
    (5 - data['Investment_Horizon']) * 5 +  # Shorter horizon â†’ more debt
    (100 - data['Savings_Rate']*100) * 0.1 +  # Lower saving rate â†’ prefer safer assets
    np.random.normal(0, 1.5, len(data))
).clip(0, 100)

# Mutual Fund Allocation (not just leftover)
data['MutualFund_Allocation'] = (
    100 - data['Equity_Allocation'] - data['Debt_Allocation']
).clip(0, 100)

# Normalizing so total = 100
total_alloc = data['Equity_Allocation'] + data['Debt_Allocation'] + data['MutualFund_Allocation']
data['Equity_Allocation'] = data['Equity_Allocation'] / total_alloc * 100
data['Debt_Allocation'] = data['Debt_Allocation'] / total_alloc * 100
data['MutualFund_Allocation'] = data['MutualFund_Allocation'] / total_alloc * 100

# Step 3: Stage 2 - Multi-output Preparation

X2 = data.drop(['User_ID', 'Recommended_Investment_Percentage',
                'Equity_Allocation', 'Debt_Allocation', 'MutualFund_Allocation'], axis=1)

y2 = data[['Equity_Allocation', 'Debt_Allocation', 'MutualFund_Allocation']]

# Train-Test Split
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)

# Scaling
X2_train = scaler.fit_transform(X2_train)
X2_test = scaler.transform(X2_test)

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.multioutput import MultiOutputRegressor # Import MultiOutputRegressor
gb2_model = MultiOutputRegressor(GradientBoostingRegressor(random_state=42))
gb2_model.fit(X2_train, y2_train)

gb2_pred = gb2_model.predict(X2_test)

print("\nGradient Boosting Stage 2")
for i, col in enumerate(['Equity_Allocation', 'Debt_Allocation', 'MutualFund_Allocation']):
    print(f"{col} MAE:", mean_absolute_error(y2_test.iloc[:, i], gb2_pred[:, i]))
    print(f"{col} R2 Score:", r2_score(y2_test.iloc[:, i], gb2_pred[:, i]))

# Step 6: Final Investment Recommendation Example

# Example for 1 customer:
customer_idx = 14  # you can change this
recommended_percent = gb_model.predict([X_test[customer_idx]])[0] # Changed 'model' to 'gb_model'
recommended_allocation = gb2_model.predict([X2_test[customer_idx]])[0] # Changed 'multi_model' to 'gb2_model'

print("\nRecommended Investment Plan for Customer:")
print(f"Recommended % of Savings to Invest: {recommended_percent:.2f}%")
print(f"Allocation => Equity: {recommended_allocation[0]:.2f}%, Debt: {recommended_allocation[1]:.2f}%, Mutual Fund: {recommended_allocation[2]:.2f}%")

# The variable gb2_model was used to store the trained MultiOutputRegressor
# Assign gb2_model to stage2_model before saving it.
stage2_model = gb2_model
joblib.dump(stage2_model, "stage2_gbm.pkl")

"""# STAGE 3

"""


import yfinance as yf
import pandas as pd

# List of example stocks
stock_list = ["RELIANCE.NS", "INFY.NS", "TCS.NS", "HDFCBANK.NS", "BAJFINANCE.NS"]

stock_data = []

for ticker in stock_list:
    stock = yf.Ticker(ticker)
    info = stock.info
    stock_data.append({
        "Product_ID": ticker,
        "Product_Type": "Equity",
        "Product_Name": info.get('longName', ''),
        "Category": "Stock",
        "Risk_Level": "High" if info.get('beta', 1) > 1 else "Medium",
        "Expected_Return (%)": round(info.get('forwardPE', 10),2),
        "Investment_Horizon (Years)": 5,
        "Volatility_Level": "High" if info.get('beta', 1) > 1 else "Medium"
    })

df_stocks = pd.DataFrame(stock_data)
print(df_stocks)

import requests
from bs4 import BeautifulSoup

url = "https://www.amfiindia.com/net-asset-value/nav-history"
headers = {'User-Agent': 'Mozilla/5.0'}

response = requests.get("https://www.amfiindia.com/spages/NAVAll.txt", headers=headers)
data = response.text

mf_data = []

for line in data.split("\n"):
    tokens = line.strip().split(";")
    if len(tokens) > 5:
        mf_data.append({
            "Product_ID": tokens[0],
            "Product_Type": "Mutual Fund",
            "Product_Name": tokens[3],
            "Category": "General Mutual Fund",
            "Risk_Level": "Medium",  # Static for now, you can classify later
            "Expected_Return (%)": 8,  # Placeholder
            "Investment_Horizon (Years)": 3,
            "Volatility_Level": "Medium"
        })

df_mf = pd.DataFrame(mf_data)
print(df_mf.head())

# Combine into Stage 3 Dataset
df_stage3 = pd.concat([df_stocks, df_mf], ignore_index=True)
df_stage3.to_csv("Stage3_Dynamic_Products.csv", index=False)

print("âœ… Stage 3 Dataset Saved: Stage3_Dynamic_Products.csv")

import pandas as pd

# Load the Stage 3 Dataset
df_stage3 = pd.read_csv("Stage3_Dynamic_Products.csv")

print(df_stage3.head())

# Example Customer Profile (from Stage 2)
customer_info = {
    'Risk_Tolerance': 'Medium',
    'Investment_Horizon': 5,  # in years
    'Equity_Allocation': 15,  # %
    'MutualFund_Allocation': 35,  # %
    'Debt_Allocation': 50   # %
}

def recommend_products(product_type, allocation, customer_info, top_n=3):
    df_filtered = df_stage3[
        (df_stage3['Product_Type'] == product_type) &
        (df_stage3['Risk_Level'] == customer_info['Risk_Tolerance']) &
        (df_stage3['Investment_Horizon (Years)'] <= customer_info['Investment_Horizon'])
    ]

    if df_filtered.empty:
        return f"No {product_type} products available for this customer profile."

    df_recommend = df_filtered.sort_values(
        by='Expected_Return (%)', ascending=False
    ).head(top_n)

    return df_recommend[['Product_Name', 'Expected_Return (%)', 'Risk_Level', 'Volatility_Level']]

print("ðŸ”µ Recommended Stocks (Equity):")
print(recommend_products('Equity', customer_info['Equity_Allocation'], customer_info))

print("\nðŸŸ£ Recommended Mutual Funds:")
print(recommend_products('Mutual Fund', customer_info['MutualFund_Allocation'], customer_info))

print("\nðŸŸ¢ Recommended Debt Instruments:")
print(recommend_products('Debt', customer_info['Debt_Allocation'], customer_info))
